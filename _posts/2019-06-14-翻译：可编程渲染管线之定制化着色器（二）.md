## 前言

翻译：可编程渲染管线之定制化着色器（二）

这篇文章是翻译自<https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-shaders/>

关于动态批处理和GPU Instancing 可以参考<https://zhuanlan.zhihu.com/p/34499251>



## 定制化Shaders  HLSL与CoreLibrary

* 编写一个HLSL着色器
* 定义constant buffers
* 使用渲染管线Core Library
* 支持动态批处理和GPU Instancing

这是Unity的可编程渲染管线系列教程的第二篇文章。本文是关于使用HLSL创建一个shader，以及在单个DrawCall里通过batch批处理，高效渲染多个物体。

本篇教程使用的Unity版本是 2018.3.0f2。

![img](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-shaders/tutorial-image.jpg)

*256 spheres, a single draw call.*



### 1 定制Unity Shader

虽然我们已经可以在渲染管线中使用默认的unlit shader，但是高效利用定制渲染管线，也需要创建定制化shader。所以我们将会独立创建一个shader 取代 Unity的默认的unlit shader。（nontrivial 重要的）


#### 1.1 创建一个shader

shader资源可以通过Asset/Create/Shader 目录来创建。创建一个unlit shader好了，因为我们打算从零开始写代码，所以我们删除创建出来的shader的默认代码，并把这个资源命名为Unlit。

![img](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-shaders/custom-unlit-shader/unlit-shader.png)

*Unlit shader asset*

shader的基础教程在这个网址，如果你不熟悉编写shader那么就去读一读。让一个shader工作起来的最少需要定义一个shader块，这个shader块有一个属性块properties block 加上一个子着色器块subshader block（有一个pass block在 subshader里边）。在填上Shader的关键字My Pipeline/Unlit 之后，Unity会把这个shader变成一个默认的白色unlit shader 。接着就可以在材质里的shader的下拉框中找到。

```
Shader "My Pipeline/Unlit" {
	Properties {}
	SubShader {
		Pass {}
	}
}
```

修改Unlit Opaque材质，让它使用新的shader。这会让材质变成白色，即使shader都还没开始写。

![img](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-shaders/custom-unlit-shader/unlit-opaque-material.png)



#### 1.2 HLSL

为了编写shader，我们必须在pass块中放入一段程序。Unity支持GLSL和HLSL两种代码语言。GLSL用在默认的shader还有

？？？

HLSL的新渲染管线则使用了HLSL。所以我们的渲染管线也会使用HLSL。这意味着我们必须把我们的代码放在 HLSLPROGRAM 和 ENDHLSL 中间。

```
		Pass {
			HLSLPROGRAM
			
			ENDHLSL
		}
```



> GLSL 和 HLSL有什么不同呢
>
> 实际上，Unity为两种语言使用相同的语义（定义UnityShader专用的语言），并且根据目标平台的不同，会处理UnityShader代码转化成适合目标平台工作的shader代码的工作。
>
> 最大的不同点就是GLSL会隐式的include一些代码，而HLSL不会隐式的帮我们处理这些事情，这就要求我们使用HLSL的时候，需要做什么工作，就需要显式的include什么文件。这一点不错，因为旧版本的GLSL的include文件被一些老旧过时的代码给拖累的。我们将会使用更新的HLSL include文件。



Unity的shader最少需要一个顶点函数和一个片元函数。这两个函数都用 pragma 来定义。我们定义顶点函数为 UnlitPassVertex， 片元函数为 UnlitPassFragment 。但我们不会把这两个函数的代码直接放在shader文件里。我们把HLSL文件单独放在一个“include文件”中（意思是代码放在另外一个文件里，然后shader include这个代码文件，就称代码文件为include文件）。这个include文件起名为 Unlit，以 hlsl 为后缀。把它放在和 Unlit 一样的文件夹下。在使用 pragma定义顶点函数、片元函数后，就可以include这个文件了。

```
			HLSLPROGRAM
			
			#pragma vertex UnlitPassVertex
			#pragma fragment UnlitPassFragment
			
			#include "Unlit.hlsl"
			
			ENDHLSL
```





不幸的是，Unity并没有一个方便的选项来让我们创建 hlsl 文件资源。我们必须自己来创建，例如通过复制 Unlit.shader 文件，然后改拓展名，再把shader代码移除。





在这个include文件里（也就是编写顶点函数、片元函数的 hlsl 文件），会设置一个 guard 标志来避免这个文件在被include多次的情况下产生重复代码。最好在每一个include文件都这么做。

```
#ifndef MYRP_UNLIT_INCLUDED
#define MYRP_UNLIT_INCLUDED

#endif // MYRP_UNLIT_INCLUDED
```



（弄完文件之后就是具体的编写hlsl代码了）

在顶点函数中，我们最少需要知道顶点位置，顶点位置是必须输出到裁剪空间位置的。所以我们为顶点函数定义两个结构体，input结构体和output结构体。这两个结构体都带有一个 float4的变量，表示位置。

```
#ifndef MYRP_UNLIT_INCLUDED
#define MYRP_UNLIT_INCLUDED

struct VertexInput {
	float4 pos : POSITION;
};

struct VertexOutput {
	float4 clipPos : SV_POSITION;
};

#endif // MYRP_UNLIT_INCLUDED
```



接着我们来实现 UnlitPassVertex 这个顶点函数。现在我们直接把局部空间的顶点位置输出为裁剪空间的位置。这是不正确的空间转换，但这是最快的方式来获取一个编译好的shader。我们将在稍后纠正。

```
struct VertexOutput {
	float4 clipPos : SV_POSITION;
};

VertexOutput UnlitPassVertex (VertexInput input) {
	VertexOutput output;
	output.clipPos = input.pos;
	return output;
}

#endif // MYRP_UNLIT_INCLUDED
```



（在片元函数里）目前我们保持输出颜色为默认的白色即可。所以片元处理函数只需要返回一个 1，float4 类型的值。顶点函数的输出后作为片元函数的输入，所以要把它作为参数，即使我们现在用不到。

```
VertexOutput UnlitPassVertex (VertexInput input) {
	VertexOutput output;
	output.clipPos = input.pos;
	return output;
}

float4 UnlitPassFragment (VertexOutput input) : SV_TARGET {
	return 1;
}

#endif // MYRP_UNLIT_INCLUDED
```



> 我们是否使用half 或者 float
>
> 大部分移动设备GPU都支持这两种precision types精度类型， half会更加高效一些。所以如果你正在为移动设备做优化工作，那么应该尽可能的使用half。 如果结果是可以接收的情况下,那么一般规则是 只对positions位置和texture coordinate纹理坐标使用float，其他的则全部用half。（The rule is to use **float** for positions and texture coordinate only and **half** for everything else, provided that the results are acceptable.）
>
> （Provided that 如果是、假如）
>
> 如果目标不是移动平台，精度并不是一个大问题。因为GPU总是会使用float，即使我们写half也是一样。之后的教程基本都是写float的。
>
> 其实还有一个fixed精度，但它只被一些比较老的设备支持，基本上现在的app不会考虑安装在这些设备上，（所以基本可以忽略了），fixed这个精度通常是等同于half的。



#### 1.3 Transformation Matrices 矩阵变换

现在我们有了一个编译成功的shader了，但它尚未产生正确的结果。下一步就是把顶点位置转化到正确的空间位置。如果我们有一个MVP矩阵，我们可以直接从局部空间转化到裁剪空间，但Unity并没有为我们提供这么一个矩阵，Unity为我们提供了局部空间到世界空间的矩阵。Unity希望我们的shader有一个 float4*4 的unity_ObjectToWorld 变量来存储矩阵。因为我们是用HLSL工作的，所以我们必须自己来定义这个变量。然后才可以在顶点函数中使用它转化位置到世界空间的位置，并使用这个世界空间的位置作为输出结果。



```
float4x4 unity_ObjectToWorld;

struct VertexInput {
	float4 pos : POSITION;
};

struct VertexOutput {
	float4 clipPos : SV_POSITION;
};

VertexOutput UnlitPassVertex (VertexInput input) {
	VertexOutput output;
	float4 worldPos = mul(unity_ObjectToWorld, input.pos);
	output.clipPos = worldPos;
	return output;
}
```



接着我们需要转化世界空间到裁剪空间。这个工作可以被VP矩阵完成。Unity也为我们提供了float4*4 unity_MatrixVP 变量来作为VP矩阵，这样就完成了空间转化

```
float4x4 unity_MatrixVP;
float4x4 unity_ObjectToWorld;

…

VertexOutput UnlitPassVertex (VertexInput input) {
	VertexOutput output;
	float4 worldPos = mul(unity_ObjectToWorld, input.pos);
	output.clipPos = mul(unity_MatrixVP, worldPos);
	return output;
}
```



> 我修改了代码，但它还没有生效？
>
> 

我们的shader现在已经正确执行了。所有使用这个 unlit material 的物体又是可见的了，显示为白色。但是我们的空间转化可以更加高效，因为空间转化是使用一个4D的位置向量来做矩阵乘法。向量的第四个值总是为1，通过显式声明，我们可以使编译器优化计算。

```
float4 worldPos = mul(unity_ObjectToWorld, float4(input.pos.xyz, 1.0));v
```



#### 1.4 Constant Buffer 常量缓存区

Unity并没有为我们提供MVP矩阵，因为 M 和 VP 矩阵的相乘是避免的。除此之外， VP矩阵能够被同一帧内，被同一个摄像机所绘制的所有物体所复用。Unity着色器利用了这一点并且把这个矩阵放在一个Constant Buffer中。虽然我们定义它们为变量，但是它们的数据在绘制一个图形的时间段内是保持常量的。通常会保持更长的时间段。VP矩阵被放入一个 per-frame的缓冲区中，而 M 矩阵则被放入一个 per-draw 的缓冲区中。（每次调用Draw命令，per-draw缓冲区内容保持不变。per-frame 同理，在同一帧内 VP矩阵保持不变，实现复用）。

虽然并没有严格要求把shader变量放在Constant Buffer中，但这么做确实可以更有效地修改在相同常量缓冲区的数据。至少在图形API的支持下是这种情况的（指HLSL），OpenGL则不是这样。

为了尽可能地高效，我们也会利用Constant Buffer。Unity把 VP矩阵放在 UnityPerFrame的cbuffer中，把 M 矩阵放在 UnityPerDraw的CBuffer中。其实有更多的数据放在这些cbuffer中，但在我们的渲染管道里暂时还不需要这么做。除了cbuffer关键字不同，一个cbuffer的定义就像struct一样，其中变量也保持是可以被访问的。

```
cbuffer UnityPerFrame {
	float4x4 unity_MatrixVP;
};

cbuffer UnityPerDraw {
	float4x4 unity_ObjectToWorld;
}
```



#### 1.5 Core Library

因为cbuffer并没有使所有平台受益，所以Unity的shader依赖宏 只在需要的时候才使用它们。

？？？

比起直接写cbuffer，我们使用 CBUFFER_START 宏加上一个名字参数来替代。对应的CBUFFER_END宏取代了原本cbuffer的结束方式。

（意思是cbuffer得谨慎使用吧，感觉cbuffer复用得好应该所有平台都能有收益才对，这么说的话，可能有一些隐含的问题？ ）

```
CBUFFER_START(UnityPerFrame)
	float4x4 unity_MatrixVP;
CBUFFER_END

CBUFFER_START(UnityPerDraw)
	float4x4 unity_ObjectToWorld;
CBUFFER_END
```

上面的这种写法会导致一个编译错误。因为这两个宏还没有被定义。比起弄明白什么时候是合适的情况来使用cbuffer和我们自己来定义宏，我们更倾向于利用Unity的Core Library。CoreLibrary可以通过PackageManagerWindow来添加到我们的项目中。转到 AllPackages liebiao ，在Advanced下启用Show preview packages。然后选择 Render-pipelines.core 然后安装它。我正在使用4.6.0的预览版，Unity2018.3会使用更高的版本。



![img](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-shaders/custom-unlit-shader/core-package.png)



现在我们可以include 包含进 common library functionality 公共库函数。我们可以访问通过*Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl*. 它定义了多个有用的函数和宏，还有许多cbuffer的宏，所以在使用这些定义好的宏前 先include它吧

```
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"

CBUFFER_START(UnityPerFrame)
float4x4 unity_MatrixVP;
CBUFFER_END
```

> 这些宏是如何工作的呢？
>
> 通过打开core library package的 Common.hlsl 文件，我们可以就能了解宏是如何生效的。原来Common.hlsl从它的API子文件夹中include了许多 特定API的文件。这些文件定义了宏。



#### 1.6  Compilation Target Level 

我们的shader再一次生效了，至少对大部分平台而言。在include core library之后，我们的shader在OpenGL ES2 上编译失败。 这确实会发生，因为默认情况下Unity 对OpenGL ES 2使用一个shader编译器，这个shader编译器与core library一起时是不生效的。修复这个问题可以通过向shader中添加一句

**#pragma prefer_hlslcc gles** 

增加上述这一句代码，这也是Unity在LWRP 轻量级渲染管线的做法。可以比起这么做，我们选择不支持OpenGL ES2 。 因为OpenGL ES 2 应用于一些老的移动设备。

我们选择目标平台 通过这一句代码 **#pragma target**  直接指定为3.5 而不是默认的level 2.5

```
			#pragma target 3.5
			
			#pragma vertex UnlitPassVertex
			#pragma fragment UnlitPassFragment
```



#### 1.7 Folder Struct 文件夹结构

注意 core library 的所有 HLSL的 include文件全都放在ShaderLibrary文件夹下。我们也在My Pipeline的文件夹下新建一个ShaderLibrary并且把Unlit.hlsl放入这个文件夹。shader文件则放在一个单独的文件夹Shader下。

![img](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-shaders/custom-unlit-shader/folder-structure.png)

*我的渲染管线文件夹目录结构*

为了保持我们的shader不受目录结构变化的影响，同时仍然依赖于相对路径，我们必须修改include statement，include之后的这一句声明，从原本的 Unlit.hlsl 修改成"../ShaderLibrary/Unlit.hlsl"。

```
			#include "../ShaderLibrary/Unlit.hlsl"
```





## 2 Dynamic Batching 动态批处理

既然我们已经有了一个基本的shader，我们可以用它来进一步研究如何让我们的管线渲染物体。一个问题是它的渲染能多高效？我们通过在场景中填充一堆使用一堆白色球体来测试，每一个球体都会使用 unlit shader，也就是我们之前定义的材质。可以使用几千个球体来测试，但是几十个也行。他们可以有有不同的transformation，但是scale必须统一，就是说XYZ必须相等。

![img](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-shaders/dynamic-batching/spheres.png)

*一堆白色的球体*

在通过frame debugger调查这个场景是如何被绘制的时候，我们能注意到每一个球体需要单独的draw call。这不是高效的，因为每个draw call都会引入开销，这部分开销来自于CPU与GPU交流信息的时候。理想情况下，多个球体能通过一个draw call来绘制。这是可行的。选中frame debugger的一条draw call，会给了我们一条提示。

![img](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-shaders/dynamic-batching/no-batching.png)

（补充一点，通常绘制一个物体分为两个阶段，一是CPU往GPU传递数据，设置渲染状态，称为setpass。二是GPU开始调用数据绘制图形。其中第一阶段的消耗占整个过程比第二阶段的消耗大很多，所以优化的方向就是减少CPU、GPU传递数据的次数。如果有多个可见相同物体，那么可以考虑把它们给批处理一下，多个drawcall合并成一个drawcall，这样CPU、GPU就只传递了一次数据，完成了多个物体的绘制。

批处理还可以分为静态批处理和动态批处理，不管是哪一种批处理也是有限制的，静态批处理会增大内存，动态批处理是有顶点限制的。而且传递给GPU的数据也不是越多越好，也必须考虑GPU的处理能力。

批处理的对象如果大部分不可见，那么传递整批顶点数据过去其实也是不必要的。所以批处理的使用得考虑实际情况。）



#### 2.1 Enabling Batching 开启批处理

frame debugger告诉我们动态批处理没有被使用，坑你是因为在PlayerSetting是关闭的，或者是因为深度排序的接口。 检查PlayerSetting，其中的Dynamic Batching这个选项是关闭的，但是开启的话也没有起作用。因为PlayerSetting是对Unity默认渲染管线起作用的。我们这个是定制的渲染管线。

为了给我们的渲染管线开启动态批处理，我们必须声明在渲染管线的渲染器绘制的时候，动态批处理是允许的。drawsetting包含一个 flags 的字段，我们必须设置这个 flags 为允许动态批处理。如下

```
		var drawSettings = new DrawRendererSettings(
			camera, new ShaderPassName("SRPDefaultUnlit")
		);
		drawSettings.flags = DrawRendererFlags.EnableDynamicBatching;
		drawSettings.sorting.flags = SortFlags.CommonOpaque;
```



在修改完后动态批处理仍然没有生效，但是提示的原因改变了。动态批处理即在物体被绘制前，unity把物体合并到一个mesh中。它是要求每一帧中消耗CPU时间去处理，而且这仅对small mesh有效。（也就是说物体顶点数太多是无法动态批处理的）。



球体的网格顶点数太多了，方块是足够小的，修改所有物体成方块。可以通过选中全体然后修改它们的mesh filter。

![scene](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-shaders/dynamic-batching/cubes.png)



![frame debugger](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-shaders/dynamic-batching/batched.png)



#### 2.2 Colors 多种颜色

动态批处理对于多个使用相同材质的小网格来说是生效的。但是涉及多个材质的时候，问题也就变得复杂了。为了说明这个情况，让unlit shader可以去修改颜色。增加一个颜色属性到它的 Properties block 属性块中，名字叫做“Color”，默认白色。 

```
	Properties {
		_Color ("Color", Color) = (1, 1, 1, 1)
	}
```



现在我们就可以来调整材质的颜色了，但还没有产生影响。我们增加一个 float4 _Color 的变量到我们的include文件中，之前我们是在unlitPassFragment片元函数中返回一个固定值，现在让函数返回这个颜色值。每一个材质都定义了一个颜色属性，所以颜色属性可以放在cbuffer，只在切换材质的时候，才需要改变这个cbuffer。这个cbuffer起名为UnityPerMaterial。



复制材质并设置不同的颜色，以便于区分它们。选中一些物体让它们使用新的材质。最后能看到场景中是两种颜色的方块混合在一起。





动态批处理仍然是生效的，但我们是饿到多个批处理。每个材质至少会有一个批处理，因为每一个批处理都要求不同的材质数据。通常会有更多批处理因为Unity倾向于在空间上组合物体来减少overdraw。



#### 2.3 Optional Batching  可选的批处理 

动态批处理可能会有帮助，但它也有可能没有那么大的效果，甚至可能降低效率。如果你的场景没有包含大量包含相同材质的小网格，可能关闭动态批处理会更加的合理，Unity也就不必知道是否要在每帧使用批处理技术。 所以我们增加了一个选项，我们的渲染管线是否开启动态批处理。我们的渲染管线并不使用PlayerSetting，所以我们增加了一个配置选项到 MyPipelineAsset。我们可以在Editor通过pipeline资源来配置这项数据。



在MyPipeline实例创建的时候，我们必须告诉它是否要使用动态批处理。我们会通过在它的构造函数中通过函数参数来提供这项信息。



我们不在使用MyPipeline的默认构造函数了，我们提供一个带有boolean值作为参数的公共构造方法。boolean值用来控制是否开启动态批处理。



















































































































































#### 2.3 Command Buffers



```
using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Experimental.Rendering;

public class MyPipeline : RenderPipeline {

	…

	void Render (ScriptableRenderContext context, Camera camera) {
		context.SetupCameraProperties(camera);

		var buffer = new CommandBuffer();

		context.DrawSkybox(camera);

		context.Submit();
	}
}
```



```
	var buffer = new CommandBuffer();
		context.ExecuteCommandBuffer(buffer);
```



```
	var buffer = new CommandBuffer();
		context.ExecuteCommandBuffer(buffer);
		buffer.Release();
```



```
		var buffer = new CommandBuffer();
		buffer.ClearRenderTarget(true, false, Color.clear);
		context.ExecuteCommandBuffer(buffer);
		buffer.Release();
```





![img](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-pipeline/rendering/frame-debugger-clear-command.png)





```
		CameraClearFlags clearFlags = camera.clearFlags;
		buffer.ClearRenderTarget(
			(clearFlags & CameraClearFlags.Depth) != 0,
			(clearFlags & CameraClearFlags.Color) != 0,
			camera.backgroundColor
		);
```



```
		var buffer = new CommandBuffer {
			name = camera.name
		};
```



![img](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-pipeline/rendering/frame-debugger-camera-name.png)

#### 2.4 Culling



```
	void Render (ScriptableRenderContext context, Camera camera) {
		ScriptableCullingParameters cullingParameters;
		CullResults.GetCullingParameters(camera, out cullingParameters);

		…
	}
```



```
		if (!CullResults.GetCullingParameters(camera, out cullingParameters)) {
			return;
		}
```



```
if (!CullResults.GetCullingParameters(camera, out cullingParameters)) {
			return;
		}

		CullResults cull = CullResults.Cull(ref cullingParameters, context);
```



#### 2.5 Drawing



```
		buffer.Release();

		var drawSettings = new DrawRendererSettings();

		var filterSettings = new FilterRenderersSettings();

		context.DrawRenderers(
			cull.visibleRenderers, ref drawSettings, filterSettings
		);

		context.DrawSkybox(camera);
```





```
		var filterSettings = new FilterRenderersSettings(true);
```

```
		var drawSettings = new DrawRendererSettings(
			camera, new ShaderPassName("SRPDefaultUnlit")
		);
```







![img](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-pipeline/rendering/opaque-only.jpg)



![img](https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-pipeline/rendering/frame-debugger-draw.png)













