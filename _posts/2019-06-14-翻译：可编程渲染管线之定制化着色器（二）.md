---
layout:     post
title:      翻译：可编程渲染管线之定制化着色器（二）
date:       2019-06-14
author:     BAJIAObujie
header-img: img/post-bg-cook.jpg
catalog: true




---

## 前言

翻译：可编程渲染管线之定制化着色器（二）

这篇文章是翻译自<https://catlikecoding.com/unity/tutorials/scriptable-render-pipeline/custom-shaders/>

关于动态批处理和GPU Instancing 可以参考<https://zhuanlan.zhihu.com/p/34499251>



## 定制化Shaders  HLSL与CoreLibrary

* 编写一个HLSL着色器
* 定义constant buffers
* 使用渲染管线Core Library
* 支持动态批处理和GPU Instancing

这是Unity的可编程渲染管线系列教程的第二篇文章。本文是关于使用HLSL创建一个shader，以及在单个DrawCall里通过batch批处理，高效渲染多个物体。

本篇教程使用的Unity版本是 2018.3.0f2。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP11/1.jpg)

*256 spheres, a single draw call.*



### 1 定制Unity Shader

虽然我们已经可以在渲染管线中使用默认的unlit shader，但是高效利用定制渲染管线，也需要创建定制化shader。所以我们将会独立创建一个shader 取代 Unity的默认的unlit shader。（nontrivial 重要的）


#### 1.1 创建一个shader

shader资源可以通过Asset/Create/Shader 目录来创建。创建一个unlit shader好了，因为我们打算从零开始写代码，所以我们删除创建出来的shader的默认代码，并把这个资源命名为Unlit。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/2.jpg)

*Unlit shader asset*

shader的基础教程在这个网址，如果你不熟悉编写shader那么就去读一读。让一个shader工作起来的最少需要定义一个shader块，这个shader块有一个属性块properties block 加上一个子着色器块subshader block（有一个pass block在 subshader里边）。在填上Shader的关键字My Pipeline/Unlit 之后，Unity会把这个shader变成一个默认的白色unlit shader 。接着就可以在材质里的shader的下拉框中找到。

```
Shader "My Pipeline/Unlit" {
	Properties {}
	SubShader {
		Pass {}
	}
}
```

修改Unlit Opaque材质，让它使用新的shader。这会让材质变成白色，即使shader都还没开始写。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/3.jpg)



#### 1.2 HLSL

为了编写shader，我们必须在pass块中放入一段程序。Unity支持GLSL和HLSL两种代码语言。GLSL用在默认的shader，HLSL的新渲染管线则使用了HLSL。所以我们的渲染管线也会使用HLSL。这意味着我们必须把我们的代码放在 HLSLPROGRAM 和 ENDHLSL 中间。

```
		Pass {
			HLSLPROGRAM
			
			ENDHLSL
		}
```



> GLSL 和 HLSL有什么不同呢
>
> 实际上，Unity为两种语言使用相同的语义（定义UnityShader专用的语言），并且根据目标平台的不同，会处理UnityShader代码转化成适合目标平台工作的shader代码的工作。
>
> 最大的不同点就是GLSL会隐式的include一些代码，而HLSL不会隐式的帮我们处理这些事情，这就要求我们使用HLSL的时候，需要做什么工作，就需要显式的include什么文件。这一点不错，因为旧版本的GLSL的include文件被一些老旧过时的代码给拖累的。我们将会使用更新的HLSL include文件。



Unity的shader最少需要一个顶点函数和一个片元函数。这两个函数都用 pragma 来定义。我们定义顶点函数为 UnlitPassVertex， 片元函数为 UnlitPassFragment 。但我们不会把这两个函数的代码直接放在shader文件里。我们把HLSL文件单独放在一个“include文件”中（意思是代码放在另外一个文件里，然后shader include这个代码文件，就称代码文件为include文件）。这个include文件起名为 Unlit，以 hlsl 为后缀。把它放在和 Unlit 一样的文件夹下。在使用 pragma定义顶点函数、片元函数后，就可以include这个文件了。

```
			HLSLPROGRAM
			
			#pragma vertex UnlitPassVertex
			#pragma fragment UnlitPassFragment
			
			#include "Unlit.hlsl"
			
			ENDHLSL
```



不幸的是，Unity并没有一个方便的选项来让我们创建 hlsl 文件资源。我们必须自己来创建，例如通过复制 Unlit.shader 文件，然后改拓展名，再把shader代码移除。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/4.jpg)

*Unlit HLSL include file asset*

在这个include文件里（也就是编写顶点函数、片元函数的 hlsl 文件），会设置一个 guard 标志来避免这个文件在被include多次的情况下产生重复代码。最好在每一个include文件都这么做。

```
#ifndef MYRP_UNLIT_INCLUDED
#define MYRP_UNLIT_INCLUDED

#endif // MYRP_UNLIT_INCLUDED
```



（弄完文件之后就是具体的编写hlsl代码了）

在顶点函数中，我们最少需要知道顶点位置，顶点位置是必须输出到裁剪空间位置的。所以我们为顶点函数定义两个结构体，input结构体和output结构体。这两个结构体都带有一个 float4的变量，表示位置。

```
#ifndef MYRP_UNLIT_INCLUDED
#define MYRP_UNLIT_INCLUDED

struct VertexInput {
	float4 pos : POSITION;
};

struct VertexOutput {
	float4 clipPos : SV_POSITION;
};

#endif // MYRP_UNLIT_INCLUDED
```



接着我们来实现 UnlitPassVertex 这个顶点函数。现在我们直接把局部空间的顶点位置输出为裁剪空间的位置。这是不正确的空间转换，但这是最快的方式来获取一个编译好的shader。我们将在稍后纠正。

```
struct VertexOutput {
	float4 clipPos : SV_POSITION;
};

VertexOutput UnlitPassVertex (VertexInput input) {
	VertexOutput output;
	output.clipPos = input.pos;
	return output;
}

#endif // MYRP_UNLIT_INCLUDED
```



（在片元函数里）目前我们保持输出颜色为默认的白色即可。所以片元处理函数只需要返回一个 1，float4 类型的值。顶点函数的输出后作为片元函数的输入，所以要把它作为参数，即使我们现在用不到。

```
VertexOutput UnlitPassVertex (VertexInput input) {
	VertexOutput output;
	output.clipPos = input.pos;
	return output;
}

float4 UnlitPassFragment (VertexOutput input) : SV_TARGET {
	return 1;
}

#endif // MYRP_UNLIT_INCLUDED
```



> 我们是否使用half 或者 float
>
> 大部分移动设备GPU都支持这两种precision types精度类型， half会更加高效一些。所以如果你正在为移动设备做优化工作，那么应该尽可能的使用half。 如果结果是可以接收的情况下,那么一般规则是 只对positions位置和texture coordinate纹理坐标使用float，其他的则全部用half。（The rule is to use **float** for positions and texture coordinate only and **half** for everything else, provided that the results are acceptable.）
>
> （Provided that 如果是、假如）
>
> 如果目标不是移动平台，精度并不是一个大问题。因为GPU总是会使用float，即使我们写half也是一样。之后的教程基本都是写float的。
>
> 其实还有一个fixed精度，但它只被一些比较老的设备支持，基本上现在的app不会考虑安装在这些设备上，（所以基本可以忽略了），fixed这个精度通常是等同于half的。



#### 1.3 Transformation Matrices 矩阵变换

现在我们有了一个编译成功的shader了，但它尚未产生正确的结果。下一步就是把顶点位置转化到正确的空间位置。如果我们有一个MVP矩阵，我们可以直接从局部空间转化到裁剪空间，但Unity并没有为我们提供这么一个矩阵，Unity为我们提供了局部空间到世界空间的矩阵。Unity希望我们的shader有一个 float4*4 的unity_ObjectToWorld 变量来存储矩阵。因为我们是用HLSL工作的，所以我们必须自己来定义这个变量。然后才可以在顶点函数中使用它转化位置到世界空间的位置，并使用这个世界空间的位置作为输出结果。



```
float4x4 unity_ObjectToWorld;

struct VertexInput {
	float4 pos : POSITION;
};

struct VertexOutput {
	float4 clipPos : SV_POSITION;
};

VertexOutput UnlitPassVertex (VertexInput input) {
	VertexOutput output;
	float4 worldPos = mul(unity_ObjectToWorld, input.pos);
	output.clipPos = worldPos;
	return output;
}
```



接着我们需要转化世界空间到裁剪空间。这个工作可以被VP矩阵完成。Unity也为我们提供了float4*4 unity_MatrixVP 变量来作为VP矩阵，这样就完成了空间转化

```
float4x4 unity_MatrixVP;
float4x4 unity_ObjectToWorld;

…

VertexOutput UnlitPassVertex (VertexInput input) {
	VertexOutput output;
	float4 worldPos = mul(unity_ObjectToWorld, input.pos);
	output.clipPos = mul(unity_MatrixVP, worldPos);
	return output;
}
```



> 我修改了代码，但它还没有生效？
>
> 在编辑include文件的时候，Unity并不总是会对更改做出反应，这样就不会刷新shader了。这种情况发生的时候，再次尝试保存文件，如果有必要可以做一点后退操作

我们的shader现在已经正确执行了。所有使用这个 unlit material 的物体又是可见的了，显示为白色。但是我们的空间转化可以更加高效，因为空间转化是使用一个4D的位置向量来做矩阵乘法。向量的第四个值总是为1，通过显式声明，我们可以使编译器优化计算。

```
float4 worldPos = mul(unity_ObjectToWorld, float4(input.pos.xyz, 1.0));v
```



#### 1.4 Constant Buffer 常量缓存区

Unity并没有为我们提供MVP矩阵，因为 M 和 VP 矩阵的相乘是避免的。除此之外， VP矩阵能够被同一帧内，被同一个摄像机所绘制的所有物体所复用。Unity着色器利用了这一点并且把这个矩阵放在一个Constant Buffer中。虽然我们定义它们为变量，但是它们的数据在绘制一个图形的时间段内是保持常量的。通常会保持更长的时间段。VP矩阵被放入一个 per-frame的缓冲区中，而 M 矩阵则被放入一个 per-draw 的缓冲区中。（每次调用Draw命令，per-draw缓冲区内容保持不变。per-frame 同理，在同一帧内 VP矩阵保持不变，实现复用）。

虽然并没有严格要求把shader变量放在Constant Buffer中，但这么做确实可以更有效地修改在相同常量缓冲区的数据。至少在图形API的支持下是这种情况的（指HLSL），OpenGL则不是这样。

为了尽可能地高效，我们也会利用Constant Buffer。Unity把 VP矩阵放在 UnityPerFrame的cbuffer中，把 M 矩阵放在 UnityPerDraw的CBuffer中。其实有更多的数据放在这些cbuffer中，但在我们的渲染管道里暂时还不需要这么做。除了cbuffer关键字不同，一个cbuffer的定义就像struct一样，其中变量也保持是可以被访问的。

```
cbuffer UnityPerFrame {
	float4x4 unity_MatrixVP;
};

cbuffer UnityPerDraw {
	float4x4 unity_ObjectToWorld;
}
```



#### 1.5 Core Library

因为cbuffer并没有使所有平台受益，所以Unity的shader依赖宏，这些宏只有在需要的时候才使用它们。比起直接写cbuffer，我们使用 CBUFFER_START 宏加上一个名字参数来替代。对应的CBUFFER_END宏取代了原本cbuffer的结束方式。

（意思是cbuffer得谨慎使用吧，感觉cbuffer复用得好应该所有平台都能有收益才对，这么说的话，可能有一些隐含的问题？ ）

```
CBUFFER_START(UnityPerFrame)
	float4x4 unity_MatrixVP;
CBUFFER_END

CBUFFER_START(UnityPerDraw)
	float4x4 unity_ObjectToWorld;
CBUFFER_END
```

上面的这种写法会导致一个编译错误。因为这两个宏还没有被定义。比起弄明白什么时候是合适的情况来使用cbuffer和我们自己来定义宏，我们更倾向于利用Unity的Core Library。CoreLibrary可以通过PackageManagerWindow来添加到我们的项目中。转到 AllPackages liebiao ，在Advanced下启用Show preview packages。然后选择 Render-pipelines.core 然后安装它。我正在使用4.6.0的预览版，Unity2018.3会使用更高的版本。



![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/5.jpg)



现在我们可以include 包含进 common library functionality 公共库函数。我们可以访问通过*Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl*. 它定义了多个有用的函数和宏，还有许多cbuffer的宏，所以在使用这些定义好的宏前 先include它吧

```
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"

CBUFFER_START(UnityPerFrame)
float4x4 unity_MatrixVP;
CBUFFER_END
```

> 这些宏是如何工作的呢？
>
> 通过打开core library package的 Common.hlsl 文件，我们可以就能了解宏是如何生效的。原来Common.hlsl从它的API子文件夹中include了许多 特定API的文件。这些文件定义了宏。



#### 1.6  Compilation Target Level 

我们的shader再一次生效了，至少对大部分平台而言。在include core library之后，我们的shader在OpenGL ES2 上编译失败。 这确实会发生，因为默认情况下Unity 对OpenGL ES 2使用一个shader编译器，这个shader编译器与core library一起时是不生效的。修复这个问题可以通过向shader中添加一句

**#pragma prefer_hlslcc gles** 

增加上述这一句代码，这也是Unity在LWRP 轻量级渲染管线的做法。可以比起这么做，我们选择不支持OpenGL ES2 。 因为OpenGL ES 2 应用于一些老的移动设备。

我们选择目标平台 通过这一句代码 **#pragma target**  直接指定为3.5 而不是默认的level 2.5

```
			#pragma target 3.5
			
			#pragma vertex UnlitPassVertex
			#pragma fragment UnlitPassFragment
```



#### 1.7 Folder Struct 文件夹结构

注意 core library 的所有 HLSL的 include文件全都放在ShaderLibrary文件夹下。我们也在My Pipeline的文件夹下新建一个ShaderLibrary并且把Unlit.hlsl放入这个文件夹。shader文件则放在一个单独的文件夹Shader下。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/6.jpg)

*我的渲染管线文件夹目录结构*

为了保持我们的shader不受目录结构变化的影响，同时仍然依赖于相对路径，我们必须修改include statement，include之后的这一句声明，从原本的 Unlit.hlsl 修改成"../ShaderLibrary/Unlit.hlsl"。

```
			#include "../ShaderLibrary/Unlit.hlsl"
```





## 2 Dynamic Batching 动态批处理

既然我们已经有了一个基本的shader，我们可以用它来进一步研究如何让我们的管线渲染物体。一个问题是它的渲染能多高效？我们通过在场景中填充一堆使用一堆白色球体来测试，每一个球体都会使用 unlit shader，也就是我们之前定义的材质。可以使用几千个球体来测试，但是几十个也行。他们可以有有不同的transformation，但是scale必须统一，就是说XYZ必须相等。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/7.jpg)

*一堆白色的球体*

在通过frame debugger调查这个场景是如何被绘制的时候，我们能注意到每一个球体需要单独的draw call。这不是高效的，因为每个draw call都会引入开销，这部分开销来自于CPU与GPU交流信息的时候。理想情况下，多个球体能通过一个draw call来绘制。这是可行的。选中frame debugger的一条draw call，会给了我们一条提示。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/8.jpg)

（补充一点，通常绘制一个物体分为两个阶段，一是CPU往GPU传递数据，设置渲染状态，称为setpass。二是GPU开始调用数据绘制图形。其中第一阶段的消耗占整个过程比第二阶段的消耗大很多，所以优化的方向就是减少CPU、GPU传递数据的次数。如果有多个可见相同物体，那么可以考虑把它们给批处理一下，多个drawcall合并成一个drawcall，这样CPU、GPU就只传递了一次数据，完成了多个物体的绘制。

批处理还可以分为静态批处理和动态批处理，不管是哪一种批处理也是有限制的，静态批处理会增大内存，动态批处理是有顶点限制的。而且传递给GPU的数据也不是越多越好，也必须考虑GPU的处理能力。

批处理的对象如果大部分不可见，那么传递整批顶点数据过去其实也是不必要的。所以批处理的使用得考虑实际情况。）



#### 2.1 Enabling Batching 开启批处理

frame debugger告诉我们动态批处理没有被使用，坑你是因为在PlayerSetting是关闭的，或者是因为深度排序的接口。 检查PlayerSetting，其中的Dynamic Batching这个选项是关闭的，但是开启的话也没有起作用。因为PlayerSetting是对Unity默认渲染管线起作用的。我们这个是定制的渲染管线。

为了给我们的渲染管线开启动态批处理，我们必须声明在渲染管线的渲染器绘制的时候，动态批处理是允许的。drawsetting包含一个 flags 的字段，我们必须设置这个 flags 为允许动态批处理。如下

```
		var drawSettings = new DrawRendererSettings(
			camera, new ShaderPassName("SRPDefaultUnlit")
		);
		drawSettings.flags = DrawRendererFlags.EnableDynamicBatching;
		drawSettings.sorting.flags = SortFlags.CommonOpaque;
```



在修改完后动态批处理仍然没有生效，但是提示的原因改变了。动态批处理即在物体被绘制前，unity把物体合并到一个mesh中。它是要求每一帧中消耗CPU时间去处理，而且这仅对small mesh有效。（也就是说物体顶点数太多是无法动态批处理的）。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/9.jpg)

*Too many vertices to batch*

球体的网格顶点数太多了，方块是足够小的，修改所有物体成方块。可以通过选中全体然后修改它们的mesh filter。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/10.jpg)



![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/11.jpg)



#### 2.2 Colors 多种颜色

动态批处理对于多个使用相同材质的小网格来说是生效的。但是涉及多个材质的时候，问题也就变得复杂了。为了说明这个情况，让unlit shader可以去修改颜色。增加一个颜色属性到它的 Properties block 属性块中，名字叫做“Color”，默认白色。 

```
	Properties {
		_Color ("Color", Color) = (1, 1, 1, 1)
	}
```

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/12.jpg)

现在我们就可以来调整材质的颜色了，但还没有产生影响。我们增加一个 float4 _Color 的变量到我们的include文件中，之前我们是在unlitPassFragment片元函数中返回一个固定值，现在让函数返回这个颜色值。每一个材质都定义了一个颜色属性，所以颜色属性可以放在cbuffer，只在切换材质的时候，才需要改变这个cbuffer。这个cbuffer起名为UnityPerMaterial。

```
CBUFFER_START(UnityPerDraw)
	float4x4 unity_ObjectToWorld;
CBUFFER_END

CBUFFER_START(UnityPerMaterial)
	float4 _Color;
CBUFFER_END

struct VertexInput {
	float4 pos : POSITION;
};

…

float4 UnlitPassFragment (VertexOutput input) : SV_TARGET {
	return _Color;
}
```



复制材质并设置不同的颜色，以便于区分它们。选中一些物体让它们使用新的材质。最后能看到场景中是两种颜色的方块混合在一起。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/13.jpg)

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/14.jpg)

*Two materials, four batches.*

动态批处理仍然是生效的，但我们是饿到多个批处理。每个材质至少会有一个批处理，因为每一个批处理都要求不同的材质数据。通常会有更多批处理因为Unity倾向于在空间上组合物体来减少overdraw。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/15.jpg)

*No batching because of different materials.*

#### 2.3 Optional Batching  可选的批处理 

动态批处理可能会有帮助，但它也有可能没有那么大的效果，甚至可能降低效率。如果你的场景没有包含大量包含相同材质的小网格，可能关闭动态批处理会更加的合理，Unity也就不必知道是否要在每帧使用批处理技术。 所以我们增加了一个选项，我们的渲染管线是否开启动态批处理。我们的渲染管线并不使用PlayerSetting，所以我们增加了一个配置选项到 MyPipelineAsset。我们可以在Editor通过pipeline资源来配置这项数据。

```
	[SerializeField]
	bool dynamicBatching;
```

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/16.jpg)

*Dynamic batching enabled.*

在MyPipeline实例创建的时候，我们必须告诉它是否要使用动态批处理。我们会通过在它的构造函数中通过函数参数来提供这项信息。

```
	protected override IRenderPipeline InternalCreatePipeline () {
		return new MyPipeline(dynamicBatching);
	}
```



我们不在使用MyPipeline的默认构造函数了，我们提供一个带有boolean值作为参数的公共构造方法。boolean值用来控制是否开启动态批处理。我们在构造函数设置draw flags，并记录在一个字段中。

```
	DrawRendererFlags drawFlags;

	public MyPipeline (bool dynamicBatching) {
		if (dynamicBatching) {
			drawFlags = DrawRendererFlags.EnableDynamicBatching;
		}
	}
```

在render中把flags设置到draw setting。

```
		drawSettings.flags = drawFlags;
```

注意在编辑器下调整了MyPipeline的动态批处理的选项，Unity是否批处理会立即生效。每次我们调整，都会导致创建出一个新的渲染管线实例。

## 3 GPU Instancing

动态批处理性不是我们在每帧中减少draw call的唯一方式。另外一种方式是使用GPU instancing。GPU instancing也就是CPU通知GPU在一个 draw call 中多次去绘制一个明确的“网格材质”。这样就可以结合那些使用同一网格和材质的物体，同时不需要构建一个新的网格。而且也取消了网格大小的限制。

（

摘抄

虽然实例化的物体共享相同的网格和材质，但您可以使用MaterialPropertyBlock API为每一个物体设置单独的着色器属性。

）

#### 3.1 Optional Instancing 是否启用GPU实例化

GPU instancing 是默认开启的。我们需要覆写它，这样就方便比较开启或不开启，两种情况下的结果。给MyPipeline资源增加一个新的选项，在脚本里添加一个字段，并且修改构造函数。

```
	[SerializeField]
	bool instancing;
	
	protected override IRenderPipeline InternalCreatePipeline () {
		return new MyPipeline(dynamicBatching, instancing);
	}
```

在MyPipeline的构造函数中，也为GPU instancing设置标志位。flags的值是DrawRenderFlags.EnableInstancing。我们通过操作符“ | ”传递到drawflags。这样动态批处理和GPU Instancing就同时开启了。在它们都开启的情况下，Unity更倾向于GPU Instancing。

```
	public MyPipeline (bool dynamicBatching, bool instancing) {
		if (dynamicBatching) {
			drawFlags = DrawRendererFlags.EnableDynamicBatching;
		}
		if (instancing) {
			drawFlags |= DrawRendererFlags.EnableInstancing;
		}
	}
```

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/17.jpg)

*Instancing enabled, dynamic batching disabled.*

#### 3.2 Material Support 材质支持

GPU实例化 开启了并不意味这objects会自动实例化。它还必须被材质所支持。因为实例化并不总是需要的。它是可选的，这要求两个shader的变体。一个支持实例化另一个不支持。我们可以创建要求的shader变体通过添加一句代码到我们的shader中 #pragma multi_compile_instancing 。这产生了两个shader变体，其中一个变体定义了 INSTANCING_ON关键字，另一个则没有。

			#pragma target 3.5
			
			#pragma multi_compile_instancing
			
			#pragma vertex UnlitPassVertex
			#pragma fragment UnlitPassFragment
修改了shader后，材质也相应的出现了一个新的配置选项：Enable GPU Instancing。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/18.jpg)

*Material with instancing enabled.*

#### 3.3 Shader Support 着色器支持

在GPU Instancing开启的情况下，GPU使用相同的constant data，多次去绘制相同的mesh。但是 M 矩阵也是这一部分数据的一部分。但是每个物体应该有不同的M矩阵。为了解决这个问题，一个包含许多矩阵的数组必须被放在cbuffer中，每个实例被绘制的时候使用自己独特的索引，这个索引能用来从矩阵数组中取到正确的m矩阵。

现在存在两种情况，在不启用GPU Instancing的情况下，我们使用unity_ObjectToWorld。启用GPU Instancing的情况下使用矩阵数组。为了保持在两种情况下的顶点函数的代码相同，我们会为矩阵定义一个宏 UNITY_MATRIX_M，因为CoreLibrary有一个includefile 已经为我们定义了宏来支持GPU Instancing. 它也重新定义了UNITY_MATRIX_M 来使用矩阵数组。

（也就是说没有开启GPU 实例化的时候，我们把UNITY_MATRIX_M 定义了，开启GPU实例化的时候，因为core库由一个包含文件include file ，这个文件也定义了相关的宏，其中定义的一个宏UNITY_MATRIX_M 就应用了帮我们从矩阵数组中取出我们需要的矩阵的方法。）

```
CBUFFER_START(UnityPerDraw)
	float4x4 unity_ObjectToWorld;
CBUFFER_END

#define UNITY_MATRIX_M unity_ObjectToWorld

…

VertexOutput UnlitPassVertex (VertexInput input) {
	VertexOutput output;
	float4 worldPos = mul(UNITY_MATRIX_M, float4(input.pos.xyz, 1.0));
	output.clipPos = mul(unity_MatrixVP, worldPos);
	return output;
}
```

CoreLibrary的include文件就是 UnityInstancing.hlsl ，因为它可能定义了 UNITY_MATRIX_M，我们必须在定义我们的宏之后才把它include进来。（这样如果启用GPU Instancing，include文件就会覆盖之前的UNITY_MATRIX_M的定义）

```
#define UNITY_MATRIX_M unity_ObjectToWorld

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/UnityInstancing.hlsl"
```

在使用GPU实例化的时候，被绘制的物体的索引被GPU添加到它的VertexData顶点数据中。UNITY_MATRIX_M是依赖于这个索引的，所以我们必须添加索引到VertexInput的结构体中，我们可以使用UNITY_VERTEX_INPUT_INSTANCE_ID 这个宏来记录这个索引。

```
struct VertexInput {
	float4 pos : POSITION;
	UNITY_VERTEX_INPUT_INSTANCE_ID
};
```

在使用UNITY_MATRIX_M这个宏之前必须获得物体的索引。可以通过UNITY_SETUP_INSTANCE_ID 这个宏来获得，这个宏需要一个input作为参数。

```
VertexOutput UnlitPassVertex (VertexInput input) {
	VertexOutput output;
	UNITY_SETUP_INSTANCE_ID(input);
	float4 worldPos = mul(UNITY_MATRIX_M, float4(input.pos.xyz, 1.0));
	output.clipPos = mul(unity_MatrixVP, worldPos);
	return output;
}
```

我们的方块们现在就是通过GPU Instancing的方式来绘制的了。像动态批处理一样，因为我们使用了不同的材质，所以最后绘制过程仍然是使用了几个批处理。要确保所有的材质都使用了GPU Instancing。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/19.jpg)

*Four instanced draw calls.*

除了局部空间到世界空间的矩阵，默认地，世界到局部空间的矩阵也被放在实例化Buffer中，这些是M矩阵的逆矩阵。在使用non-uniform scales 的时候，法线向量需要这些数据。但我们只使用uniform scales ，所以我们不需要这些额外的矩阵，我们可以通过增加这句代码到shader中来告诉Unity这一点，#pragma instancing_options assumeuniformscaling

```
			#pragma multi_compile_instancing
			#pragma instancing_options assumeuniformscaling
```

如果要支持non-uniform scale的时候 就必须使用一个没有开启这个选项的shader

（也就是说如果物体有缩放操作的时候不能使用GPU Instancing呗。）



#### 3.4 许多颜色

如果我们想要在我们的场景中容纳更多颜色，我们需要更多的材质！这也就意味着会有更多的batches。但是如果矩阵可以被放在一个cbuffer数组中，那么对于颜色来说 这应该也是有可能做到的。那么我们就可以把带有不同颜色的object 合并在单个batch中。只需要一些额外工作，这就可以被做到。



要支持每一个物体有一个独特的颜色首先要让每一个物体设置一个颜色成为可能。我们无法通过材质做到。因为这是一个所有objects 共享的一个资源。让我们为每一个object创建一个component吧，名字叫做InstancedColor，给它一个可配置的颜色字段。因为它对渲染管线来说不是特定的，所以把它的脚本文件保存在MyPipeline 文件夹外边。

```
using UnityEngine;

public class InstancedColor : MonoBehaviour {

	[SerializeField]
	Color color = Color.white;
}
```



为了覆写材质的颜色，我们必须提供带有材质属性块的物体渲染器。（To overriede the material's color, we have to provide the object's renderer component with a material property block。）创建一个新的 MaterialPropertyBlock 实例，通过SetColor方法给这个属性块一个_Color属性，然后传递它到物体的网格渲染器组件。假设在play模式下（就是点击播放按钮之后），物体的颜色保持不变。所以我们的代码要写在Awake方法中。

```
	void Awake () {
		var propertyBlock = new MaterialPropertyBlock();
		propertyBlock.SetColor("_Color", color);
		GetComponent<MeshRenderer>().SetPropertyBlock(propertyBlock);
	}
```



把InstancedColor组件添加到物体上，这样就可以看到颜色变化了。但是仅仅只在我们进入play mode的时候。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/20.jpg)

*Cube with color component.*

为了在edit mode模式下马上在场景中看到颜色改变，把设置颜色的相关代码移动到OnValidate方法。Awake方法能调用这个OnValidate方法，所以脚本中不必复制代码。

```
	void Awake () {
		OnValidate();
	}

	void OnValidate () {
		var propertyBlock = new MaterialPropertyBlock();
		propertyBlock.SetColor("_Color", color);
		GetComponent<MeshRenderer>().SetPropertyBlock(propertyBlock);
	}
```

> OnValidate什么时候调用呢？
>
> OnValidate是一个特殊的Unity的message方法。仅在edit模式，在component被加载或者改变的时候被调用。所以每次场景被加载的时候以及我们编辑component的时候，颜色就立即发生了改变。



选中所有物体添加一次组件这样就增加这个component到每个物体上，但是要确保已经存在这个组件的物体不会被重复添加组件。也让它们全部使用同样的材质。之前复制出来的另一个材质就可以被移除了，因为我们为每一个物体配置一个颜色。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/21.jpg)

*Many colors, one material.*

注意在InstancedColor组件中，我们每次设置一个颜色覆盖之前的颜色设置，都是创建一个新的MaterialPropertyBlock的实例。这不是必要的。因为每一个网格渲染器从属性块中拷贝数据，并记录到覆写的属性。这表明我们可以复用MaterialPropertyBlock，所以我们记录一个静态字段，只在需要的时候才创建它。

```
	static MaterialPropertyBlock propertyBlock;

	…

	void OnValidate () {
		if (propertyBlock == null) {
			propertyBlock = new MaterialPropertyBlock();
		}
		propertyBlock.SetColor("_Color", color);
		GetComponent<MeshRenderer>().SetPropertyBlock(propertyBlock);
	}
```



而且我们能稍微加速颜色属性的匹配通过提前取回它的属性ID，通过Shader.PropertyToID方法。每一个shader的属性名字有一个全局的标识符int值。这些的标识符可能发生改变，但是在单个session期间是保持常量的，即在play和compilation之间。（session是指点击play开始游戏 到 编译代码的这一个过程。就是每次运行可能不同，但是单次运行游戏是保持常量的。把这个值记录为静态int值。）所以我们取到它一次，并作为静态字段的默认值存储记录起来。

```
    static int colorID = Shader.PropertyToID("_Color");

	…
	
	void OnValidate () {
		if (propertyBlock == null) {
			propertyBlock = new MaterialPropertyBlock();
		}
		propertyBlock.SetColor(colorID, color);
		GetComponent<MeshRenderer>().SetPropertyBlock(propertyBlock);
	}
```

#### 3.5 Per-Instance Colors 每个物体实例都有一个单独的颜色

覆写每个物体的颜色字段导致GPU实例化被破坏。 虽然我们使用同样一个材质，但是重要的是被用于渲染的数据。因为我们已经为每个物体覆写了颜色，我们已经强制它们被分开绘制。

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/22.jpg)

*Not instanced because of color differences.*

我们把颜色信息放在array数组里边，这可以让GPU Instancing重新生效。我们的_Color属性必须像M矩阵一样使用同样的处理方式。这种情况下，我们必须显式声明。因为core库不会为任意属性而重定义宏。（arbitrary 任意的 武断的 专制的）我们手动创建一个cbuffer，通过UNITY_INSTANCE_BUFFER_START 和对应的结束宏。取名为PerInstance。在cbuffer内，我们定义 UNITY_DEFINE_INSTANCED_PROP(float4, _Color)。在没有使用GPU Instancing的时候，这就相当于一个普通的声明变量的式子 float4 _Color。如果启用GPU Instancing，就是得到一个实例数据的数组。

```
//CBUFFER_START(UnityPerMaterial)
	//float4 _Color;
//CBUFFER_END

UNITY_INSTANCING_BUFFER_START(PerInstance)
	UNITY_DEFINE_INSTANCED_PROP(float4, _Color)
UNITY_INSTANCING_BUFFER_END(PerInstance)
```

（通过上述的方法，就有两种得到颜色的方式了。当前情形可能是两种其中之一。）为了解决这个问题，我们必须通过宏 UNITY_ACCESS_INSTANCED_PROP 来访问数据，cbuffer和属性名字作为宏的参数。

```
float4 UnlitPassFragment (VertexOutput input) : SV_TARGET {
	return UNITY_ACCESS_INSTANCED_PROP(PerInstance, _Color);
}
```



在UnlitPassFragment的片元函数中，必须得到实例的索引。所以在VertexOutput中增加一个宏 UNITY_VERTEX_INPUT_INSTANCE_ID。（之前在顶点函数中使用过UNITY_SETUP_INSTANCE_ID这个宏来取得实例索引）现在再次使用这个宏UNITY_SETUP_INSTANCE_ID。为了让它生效我们必须把index索引从vertex input 拷贝到vertex output，可以通过 UNITY_TRANSFER_INSTANCE_ID 这个宏来实现。

```
struct VertexInput {
	float4 pos : POSITION;
	UNITY_VERTEX_INPUT_INSTANCE_ID
};

struct VertexOutput {
	float4 clipPos : SV_POSITION;
	UNITY_VERTEX_INPUT_INSTANCE_ID
};

VertexOutput UnlitPassVertex (VertexInput input) {
	VertexOutput output;
	UNITY_SETUP_INSTANCE_ID(input);
	UNITY_TRANSFER_INSTANCE_ID(input, output);
	float4 worldPos = mul(UNITY_MATRIX_M, float4(input.pos.xyz, 1.0));
	output.clipPos = mul(unity_MatrixVP, worldPos);
	return output;
}

float4 UnlitPassFragment (VertexOutput input) : SV_TARGET {
	UNITY_SETUP_INSTANCE_ID(input);
	return UNITY_ACCESS_INSTANCED_PROP(PerInstance, _Color);
}
```

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/23.jpg)

*Many colors, one draw.*

所有的物体最终都被合并到一个draw call中了，即使他们使用了不同的颜色。可是仍然存在一个限制，多少数据能被放入cbuffer中呢？（ The maximum instance batch size depends on how much data we vary per instance）（这一句不太好翻译，可能有些绕口，如果CPU提交一次数据到GPU是它所说的batch，那意思是最大的提交数据量取决于我们让每个实例有多大的数据变化量）除此之外，buffer的最大值根据平台的不同也是不同的。而且我们仍然受限于使用同一个网格和材质。例如混用方块和球体会导致分离出几个批处理。

（这段话意思是在讲cbuffer能存放多少数据，但是文章并没有直接回答，而是列举了几种情况，目的是想说能放多少数据真不太好说，如果使用越多个数据的变化量，那么cbuffer也就越大。平台的不同也有关系。混用不同mesh也有关系。）

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/24.jpg)

![image](https://raw.githubusercontent.com/BAJIAObujie/BAJIAObujie.github.io/master/img/TranslationSRP1/25.jpg)

*Both cubes and spheres.*

现在我们有了一个最小的shader ，这个shader能用于高效绘制许多物体。之后我们会基于此创建更多高级的shader

In the future, we will build on this foundation to create more advanced shaders.


